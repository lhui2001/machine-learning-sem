{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba12108-9e70-4e98-b9cf-2899865edfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance segmentation: https://youtu.be/lOZDTDOlqfk\n",
    "\n",
    "from simple_unet_model import simple_unet_model \n",
    "from keras.utils import normalize\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import measure, color, io\n",
    "\n",
    "\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH  = 256\n",
    "IMG_CHANNELS = 1\n",
    "\n",
    "def get_model():\n",
    "    return simple_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "\n",
    "# load the model and corresponding weights\n",
    "\n",
    "model = get_model()\n",
    "model.load_weights('file.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccae1403-0342-4b82-a2e8-75c8f1ddf925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and process the test image - image that needs to be segmented. \n",
    "test_img = cv2.imread('C:/Users/.tiff', 0)\n",
    "test_img = Image.fromarray(test_img)\n",
    "test_img = test_img.resize((IMG_HEIGHT, IMG_WIDTH))\n",
    "test_img_norm = np.expand_dims(normalize(np.array(test_img), axis=1),2)\n",
    "test_img_norm=test_img_norm[:,:,0][:,:,None]\n",
    "test_img_input=np.expand_dims(test_img_norm, 0)\n",
    "\n",
    "# predict and threshold for values above 0.7 probability\n",
    "segmented = (model.predict(test_img_input)[0,:,:,0] > 0.7).astype(np.uint8)\n",
    "\n",
    "# print testing and segmented image\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(221)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(test_img, cmap='gray')\n",
    "plt.subplot(222)\n",
    "plt.title('Segmented Image')\n",
    "plt.imshow(segmented, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# save segmented image\n",
    "plt.imsave('C:/Users/.jpg', segmented, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33300835-fc1a-4054-957d-4895e2140038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform unet image to binary image\n",
    "img = cv2.imread('C:/Users/.jpg')  \n",
    "img_grey = img[:,:,0]\n",
    "\n",
    "# threshold image to binary using OTSU. ALl thresholded pixels will be set to 255.\n",
    "ret1, thresh = cv2.threshold(img_grey, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "\n",
    "# identify background pixels using watershed \n",
    "sure_bg = cv2.dilate(opening,kernel,iterations=10)\n",
    "\n",
    "# identify foreground pixels using watershed\n",
    "dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "\n",
    "# threshold the distance transform \n",
    "ret2, sure_fg = cv2.threshold(dist_transform, 0.2*dist_transform.max(),255,0)\n",
    "\n",
    "# identify unsure region as background - foreground\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "\n",
    "# create a marker and label the regions inside using ConnectedComponents\n",
    "# For sure regions, both foreground and background will be labeled with positive numbers\n",
    "# Unknown regions will be labeled 0\n",
    "ret3, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "# rightnow the entire background pixels is given value 0\n",
    "# add 10 to all labels so that sure background is not 0, but 10\n",
    "markers = markers+10\n",
    "\n",
    "# mow, mark the region of unknown with zero\n",
    "markers[unknown==255] = 0\n",
    "\n",
    "# watershed filling\n",
    "markers = cv2.watershed(img, markers)\n",
    "\n",
    "# color boundaries in yellow. \n",
    "img[markers == -1] = [0,255,255]  \n",
    "\n",
    "img2 = color.label2rgb(markers, bg_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d338d2c9-b8ff-41c3-9eb8-aa77d65a5ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract properties of the image \n",
    "props = measure.regionprops_table(markers, intensity_image=img_grey, \n",
    "                              properties=['area',\n",
    "                                          'mean_intensity'])\n",
    "    \n",
    "import pandas as pd\n",
    "df = pd.DataFrame(props)\n",
    "\n",
    "# remove background or other regions that may be counted as objects\n",
    "df = df[df.mean_intensity > 100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f437a4a-01ac-4bff-8fa9-23f6ab51d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# properties of the image (area)\n",
    "print(df)\n",
    "\n",
    "# number of lamellopodia according to area analysis\n",
    "area = df[\"area\"].sum()\n",
    "mean = df.loc[df[\"area\"] < 1000, ['area']].mean()\n",
    "number = area / mean\n",
    "print(number)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
